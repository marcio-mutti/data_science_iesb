{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disc_Soft.Trabalho_Encerramento_Semestre.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOD8PIkXGWUCcTPvEnJrUuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcio-mutti/data_science_iesb/blob/main/Disc_Soft_Trabalho_Encerramento_Semestre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-1lA44CBSpS",
        "outputId": "548aeff1-838a-41a9-9ecb-cc8d822c42cd"
      },
      "source": [
        "!pip install odfpy\n",
        "!pip install folium --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting odfpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/73/8ade73f6749177003f7ce3304f524774adda96e6aaab30ea79fd8fda7934/odfpy-1.4.1.tar.gz (717kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 7.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 81kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 112kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 122kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 143kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 153kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 163kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 174kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 184kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 194kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 204kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 215kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 225kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 235kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 245kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 256kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 266kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 276kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 286kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 296kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 307kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 317kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 327kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 337kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 348kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 358kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 368kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 378kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 389kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 399kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 409kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 419kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 430kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 440kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 450kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 460kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 471kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 481kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 491kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 501kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 512kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 522kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 532kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 542kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 552kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 563kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 573kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 583kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 593kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 604kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 614kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 624kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 634kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 645kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 655kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 665kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 675kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 686kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 696kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 706kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 716kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 727kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from odfpy) (0.7.1)\n",
            "Building wheels for collected packages: odfpy\n",
            "  Building wheel for odfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for odfpy: filename=odfpy-1.4.1-py2.py3-none-any.whl size=160691 sha256=a0124f20267f0be63cb3c843f7253bcebb93445bf1a9a9f7d362437066c23e15\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/6b/93/ec330f2991c5f1546abf640360e5a2022f76cb16e5d99ed2fd\n",
            "Successfully built odfpy\n",
            "Installing collected packages: odfpy\n",
            "Successfully installed odfpy-1.4.1\n",
            "Collecting folium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/83/e8cb37afc2f016a1cf4caab8d22caf7fe4156c4c15230d8abc9c83547e0c/folium-0.12.1-py2.py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from folium) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from folium) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from folium) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.9->folium) (2.0.1)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.12.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: folium\n",
            "  Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seEVIyoZBdzi"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sbn\n",
        "import folium as fl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.axes import Axes\n",
        "from scipy import stats\n",
        "from sklearn import linear_model\n",
        "from requests import Session\n",
        "from zipfile import ZipFile\n",
        "from datetime import date, datetime, timedelta\n",
        "from io import BytesIO\n",
        "from math import ceil\n",
        "from bz2 import decompress\n",
        "from json import loads as JSONloads, dumps as JSONdumps\n",
        "from shapely.geometry import asShape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pxnaX07EZkA"
      },
      "source": [
        "def colorizar_county(f):\n",
        "  cor='#ffffff'\n",
        "  resultado = {'fillOpacity': 0.6, 'weight': 0}\n",
        "  td = f['properties']['tend']\n",
        "  if td != '-':\n",
        "    cor = '#ffa500'\n",
        "    if td < e_c:\n",
        "      cor = '#d62728'\n",
        "    elif td < e_m:\n",
        "      cor = '#2e8b57'\n",
        "    elif td < e_a:\n",
        "      cor = '#778899'\n",
        "  resultado['fillColor']=cor\n",
        "  return resultado\n",
        "\n",
        "def calcular_derivada(z):\n",
        "  regressor = linear_model.LinearRegression()\n",
        "  datas = np.array([datetime.strptime(x + '-01', '%Y-%m-%d').date() for x in z['year_month']])\n",
        "  redatas = np.array([(x - datas.min()).days for x in datas]).reshape(-1,1)\n",
        "  regressor.fit(X=redatas, y=z['excedente'])\n",
        "  return regressor.coef_[0]\n",
        "\n",
        "def situar_cidades(vendas_realizadas: pd.DataFrame, estoque_util: pd.DataFrame) -> pd.DataFrame:\n",
        "  expansao_vendas = pd.merge(vendas_realizadas, lojas, on=['storeid'], how='left')\n",
        "  vendas_cidades = expansao_vendas.groupby(by=['year_month', 'city', 'state']).agg({'sales_qty': 'sum'}).reset_index()\n",
        "  movimentacao_estoque = pd.merge(vendas_cidades, estoque_util, on=['city', 'state', 'year_month'], how='outer')\n",
        "  movimentacao_estoque.loc[:, 'supplied_qty'] = movimentacao_estoque.loc[:, 'supplied_qty'].fillna(0).astype(np.int32)\n",
        "  cidades_cujos_estoques_nao_diminuiram=movimentacao_estoque[movimentacao_estoque['sales_qty'].isna()]['city']\n",
        "  for cid in cidades_cujos_estoques_nao_diminuiram:\n",
        "    if len(cidades.loc[cid]) > 1:\n",
        "      print(f\"A cidade {cid} possui homônimas em outros estados\")\n",
        "    elif len(cidades.loc[cid])==0:\n",
        "      raise RuntimeError('Tem de ver isso aqui.')\n",
        "    else:\n",
        "      movimentacao_estoque.loc[(movimentacao_estoque['city']==cid)&(movimentacao_estoque['state'].isna()),'state']=cidades.loc[cid].item()\n",
        "      movimentacao_estoque.loc[(movimentacao_estoque['city'] == cid) & (movimentacao_estoque['sales_qty'].isna()), 'sales_qty'] = 0\n",
        "  movimentacao_estoque.loc[:, 'sales_qty'] = movimentacao_estoque.loc[:, 'sales_qty'].fillna(0).astype(np.int32)\n",
        "  movimentacao_estoque['venda_acumulada'] = movimentacao_estoque.groupby(by=['city', 'state'])['sales_qty'].transform(pd.Series.cumsum)\n",
        "  movimentacao_estoque['estoque_acumulado'] = movimentacao_estoque.groupby(by=['city','state'])['supplied_qty'].transform(pd.Series.cumsum)\n",
        "  movimentacao_estoque['excedente'] = movimentacao_estoque['estoque_acumulado'] - movimentacao_estoque['venda_acumulada']\n",
        "  return pd.merge(movimentacao_estoque.groupby(by=['city', 'state']).apply(calcular_derivada).rename('tendencia').reset_index(), zipes, on=['city', 'state'], how='left')\n",
        "\n",
        "def plotar_histograma_da_situacao_do_estoque_das_cidades(situacao_cidades: pd.DataFrame, axis: Axes):\n",
        "  e_c = 0\n",
        "  e_m = 0.1\n",
        "  e_a = 0.5\n",
        "  sbn.histplot(data=situacao_cidades, x='tendencia', binwidth=0.05, ax=axis)\n",
        "  axis.set_ylabel(\"N° de cidades\")\n",
        "  for pat in axis.patches:\n",
        "    if pat.get_x() < e_c:\n",
        "      pat.set_ec('darkred')\n",
        "      pat.set_fc('tab:red')\n",
        "    elif pat.get_x() < e_m:\n",
        "      pat.set_ec('darkgreen')\n",
        "      pat.set_fc('seagreen')\n",
        "    elif pat.get_x() < e_a:\n",
        "      pat.set_ec('darkslategrey')\n",
        "      pat.set_fc('lightslategrey')\n",
        "    else:\n",
        "      pat.set_ec('darkorange')\n",
        "      pat.set_fc('orange')\n",
        "\n",
        "def plotar_vendas_diarias_e_estoque(quadro_geral_de_vendas: pd.DataFrame, quadro_geral_de_estoque: pd.DataFrame, axes: list):\n",
        "  vendas_resumo = quadro_geral_de_vendas.groupby(by=['date_of_sales', 'product']).agg(vendas=('sales_qty', 'sum')).reset_index()\n",
        "  estoque_resumo = pd.merge(quadro_geral_de_estoque.groupby(by='year_month').agg({'supplied_qty': 'sum'}), quadro_geral_de_vendas.groupby(by=['year_month']).agg({'sales_qty': 'sum'}), left_index=True, right_index=True, how='inner').reset_index()\n",
        "  estoque_resumo['data_ref'] = estoque_resumo.loc[:, 'year_month'].apply(lambda z: pd.to_datetime(z + '-15'))\n",
        "  estoque_resumo['saldo'] = estoque_resumo['supplied_qty'] - estoque_resumo['sales_qty']\n",
        "  sbn.lineplot(data=vendas_resumo, x='date_of_sales', y='vendas', hue='product', palette='Set2', ax=axes[0])\n",
        "  sbn.lineplot(data=estoque_resumo, x='data_ref', y='supplied_qty', ax=axes[1], color='tab:cyan')\n",
        "  axt = axes[1].twinx()\n",
        "  sbn.lineplot(data=estoque_resumo, x='data_ref', y='saldo', ax=axt, color='tab:red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9sY7C8KBhdW",
        "outputId": "7612dc69-f0dc-4a47-b3c1-b869b81af6e9"
      },
      "source": [
        "#Carregamento de dados\n",
        "with Session() as sessao:\n",
        "  download=sessao.get('https://github.com/marcio-mutti/data_science_iesb/raw/main/Python_1/trabalho_final_software_001.zip')\n",
        "  if download.status_code != 200:\n",
        "    raise RuntimeError(\"Não foi possível recuperar arquivos do trabalho.\")\n",
        "  download_mapa_counties = sessao.get('https://github.com/marcio-mutti/data_science_iesb/raw/main/Mapas/county.geojson.zip')\n",
        "  if download_mapa_counties.status_code != 200:\n",
        "    raise RuntimeError(\"Não foi possível recuperar mapa de zipcodes dos EUA\")\n",
        "  with ZipFile(BytesIO(download.content)) as pacote:\n",
        "    with pacote.open('sales_data.csv') as arquivo_vendas:\n",
        "      vendas=pd.read_csv(arquivo_vendas,sep='\\t', names=['storeid','date_of_sales','product','sales_qty'],parse_dates=[1]).sort_values(by=['date_of_sales','storeid','product'])\n",
        "    with pacote.open('store_data.csv') as arquivo_lojas:\n",
        "      lojas=pd.read_csv(arquivo_lojas,sep='\\t',names=['storeid','city','state','zip'])\n",
        "    with pacote.open('supply_data.csv') as arquivo_estoque:\n",
        "      estoque = pd.read_csv(arquivo_estoque, sep='\\t', names=['year_month', 'city', 'supplied_qty'])        \n",
        "  print('Dados da empresa recuperados.')\n",
        "  with ZipFile(BytesIO(download_mapa_counties.content)) as pacote:\n",
        "    with pacote.open('county.geojson') as empacotado:\n",
        "      mapa_counties=JSONloads(empacotado.read())\n",
        "  print('Mapa de condados recuperado')\n",
        "zip_counties = pd.read_excel('https://github.com/marcio-mutti/data_science_iesb/raw/main/Mapas/uszipcounties.ods', engine='odf')\n",
        "zip_counties.loc[:, 'county_fips'] = zip_counties.loc[:, 'county_fips'].apply(lambda z: f\"{z:05n}\").apply(lambda z: z[:2] + '-' + z[2:])\n",
        "zipes = pd.merge(lojas.drop(labels=['storeid'], axis=1),zip_counties.drop(labels=['city','state_id'],axis=1),on=['zip'],how='left')\n",
        "print('Correlação de zips e condados recuperada.')\n",
        "populacao=pd.read_csv('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/cities/totals/sub-est2019_all.csv',usecols=[8,9,21], encoding='ISO-8859-1')\n",
        "print(\"Dados de população recuperados.\")\n",
        "ztca=pd.read_csv('https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_cousub_rel_10.txt')\n",
        "print(\"Dados de house income recuperados.\")\n",
        "vendas['year_month']=vendas['date_of_sales'].dt.strftime('%Y-%m')\n",
        "populacao['city']=populacao['NAME'].str.upper()\n",
        "print('Todos os dados recuperados.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dados da empresa recuperados.\n",
            "Mapa de condados recuperado\n",
            "Correlação de zips e condados recuperada.\n",
            "Dados de população recuperados.\n",
            "Dados de house income recuperados.\n",
            "Todos os dados recuperados.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXWxnzP3BtI5",
        "outputId": "257ae190-9b9f-4386-a539-428fd9c6959c"
      },
      "source": [
        "#Missing data??\n",
        "print(\"Dados ausentes.\")\n",
        "print(\"Vendas: {}, Lojas: {}, Estoque: {}.\".format(vendas.isna().sum().sum(),lojas.isna().sum().sum(), estoque.isna().sum().sum()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dados ausentes.\n",
            "Vendas: 0, Lojas: 0, Estoque: 0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "dEmTew_BBxXW",
        "outputId": "0dea74db-2518-4807-8634-bd1f9700ae66"
      },
      "source": [
        "#cidades e estados\n",
        "cidades=lojas[['city','state']].drop_duplicates().set_index('city')\n",
        "cidades.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FARMINGTON</th>\n",
              "      <td>MO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAUGATUCK</th>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOREST LAKE</th>\n",
              "      <td>MN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCALA</th>\n",
              "      <td>FL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LUDINGTON</th>\n",
              "      <td>MI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            state\n",
              "city             \n",
              "FARMINGTON     MO\n",
              "NAUGATUCK      CT\n",
              "FOREST LAKE    MN\n",
              "OCALA          FL\n",
              "LUDINGTON      MI"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AMVsD-EBzQL",
        "outputId": "1f239ef6-dc23-4be1-fd41-6468b269192c"
      },
      "source": [
        "#Remover informações de vendas zeradas\n",
        "vendas_zeradas=vendas[vendas['sales_qty']==0].copy()\n",
        "vendas.drop(vendas[vendas['sales_qty']==0].index,inplace=True)\n",
        "vendas.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 193999 entries, 860746 to 796255\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count   Dtype         \n",
            "---  ------         --------------   -----         \n",
            " 0   storeid        193999 non-null  int64         \n",
            " 1   date_of_sales  193999 non-null  datetime64[ns]\n",
            " 2   product        193999 non-null  object        \n",
            " 3   sales_qty      193999 non-null  int64         \n",
            " 4   year_month     193999 non-null  object        \n",
            "dtypes: datetime64[ns](1), int64(2), object(2)\n",
            "memory usage: 8.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "V_2qNigZB1OI",
        "outputId": "c1bc98d9-fa06-4353-9585-1caa090d5c77"
      },
      "source": [
        "#Lojas em municípios homônimos\n",
        "def contar_cidades(z):\n",
        "  return len(lojas_mun_homonimos[lojas_mun_homonimos['city']==z['city']])\n",
        "lojas_mun_homonimos=lojas[lojas.duplicated(subset=['city'],keep=False)].sort_values(by=['city','state'])\n",
        "lojas_mun_homonimos.drop_duplicates(subset=['city','state'], inplace=True)\n",
        "lojas_mun_homonimos['n_entradas']=lojas_mun_homonimos.apply(contar_cidades,axis=1)\n",
        "lojas_mun_homonimos.drop(lojas_mun_homonimos[lojas_mun_homonimos['n_entradas']==1].index,inplace=True)\n",
        "lojas_mun_homonimos.drop(labels=['n_entradas'], axis=1,inplace=True)\n",
        "lojas_mun_homonimos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storeid</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zip</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3203</th>\n",
              "      <td>1968</td>\n",
              "      <td>ABERDEEN</td>\n",
              "      <td>MD</td>\n",
              "      <td>21001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3709</th>\n",
              "      <td>1097</td>\n",
              "      <td>ABERDEEN</td>\n",
              "      <td>NC</td>\n",
              "      <td>28315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4293</th>\n",
              "      <td>1520</td>\n",
              "      <td>ABERDEEN</td>\n",
              "      <td>SD</td>\n",
              "      <td>57401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>2037</td>\n",
              "      <td>ABERDEEN</td>\n",
              "      <td>WA</td>\n",
              "      <td>98520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>5797</td>\n",
              "      <td>ALBANY</td>\n",
              "      <td>GA</td>\n",
              "      <td>31705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1805</th>\n",
              "      <td>3434</td>\n",
              "      <td>WOODSTOCK</td>\n",
              "      <td>IL</td>\n",
              "      <td>60098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2161</th>\n",
              "      <td>2647</td>\n",
              "      <td>WOODSTOCK</td>\n",
              "      <td>VA</td>\n",
              "      <td>22664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>350</td>\n",
              "      <td>YORK</td>\n",
              "      <td>NE</td>\n",
              "      <td>68467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1649</th>\n",
              "      <td>1529</td>\n",
              "      <td>YORK</td>\n",
              "      <td>PA</td>\n",
              "      <td>17402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3382</th>\n",
              "      <td>1144</td>\n",
              "      <td>YORK</td>\n",
              "      <td>SC</td>\n",
              "      <td>29745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>896 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      storeid       city state    zip\n",
              "3203     1968   ABERDEEN    MD  21001\n",
              "3709     1097   ABERDEEN    NC  28315\n",
              "4293     1520   ABERDEEN    SD  57401\n",
              "763      2037   ABERDEEN    WA  98520\n",
              "270      5797     ALBANY    GA  31705\n",
              "...       ...        ...   ...    ...\n",
              "1805     3434  WOODSTOCK    IL  60098\n",
              "2161     2647  WOODSTOCK    VA  22664\n",
              "2138      350       YORK    NE  68467\n",
              "1649     1529       YORK    PA  17402\n",
              "3382     1144       YORK    SC  29745\n",
              "\n",
              "[896 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "M6TkUF7XB35Y",
        "outputId": "d3c44f9a-4dcd-429f-e82c-ad1e1367022d"
      },
      "source": [
        "#Vendas mensais municipais\n",
        "vendas_lojas=pd.merge(vendas,lojas,on='storeid',how='inner')\n",
        "vendas_mensais_cidades = vendas_lojas.groupby(by=['city','state','year_month']).agg({'sales_qty':'sum'}).reset_index()\n",
        "vendas_mensais_cidades['perc']=0\n",
        "cidades_problematicas=lojas_mun_homonimos['city'].unique()\n",
        "for cid in vendas_mensais_cidades['city'].unique():\n",
        "  for ym in vendas_mensais_cidades[vendas_mensais_cidades['city']==cid]['year_month'].unique():\n",
        "    total_de_vendas=vendas_mensais_cidades[(vendas_mensais_cidades['city']==cid)&(vendas_mensais_cidades['year_month']==ym)]['sales_qty'].sum()\n",
        "    vendas_mensais_cidades.loc[(vendas_mensais_cidades['city']==cid)&(vendas_mensais_cidades['year_month']==ym),'perc']=vendas_mensais_cidades[(vendas_mensais_cidades['city']==cid)&(vendas_mensais_cidades['year_month']==ym)]['sales_qty']/total_de_vendas\n",
        "vendas_mensais_cidades"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>year_month</th>\n",
              "      <th>sales_qty</th>\n",
              "      <th>perc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABBEVILLE</td>\n",
              "      <td>LA</td>\n",
              "      <td>2019-05</td>\n",
              "      <td>17</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABBEVILLE</td>\n",
              "      <td>LA</td>\n",
              "      <td>2019-06</td>\n",
              "      <td>6</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABBEVILLE</td>\n",
              "      <td>LA</td>\n",
              "      <td>2019-07</td>\n",
              "      <td>11</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABERDEEN</td>\n",
              "      <td>MD</td>\n",
              "      <td>2019-05</td>\n",
              "      <td>15</td>\n",
              "      <td>0.145631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABERDEEN</td>\n",
              "      <td>MD</td>\n",
              "      <td>2019-06</td>\n",
              "      <td>8</td>\n",
              "      <td>0.085106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9135</th>\n",
              "      <td>ZEPHYRHILLS</td>\n",
              "      <td>FL</td>\n",
              "      <td>2019-06</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9136</th>\n",
              "      <td>ZEPHYRHILLS</td>\n",
              "      <td>FL</td>\n",
              "      <td>2019-07</td>\n",
              "      <td>23</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9137</th>\n",
              "      <td>ZION</td>\n",
              "      <td>IL</td>\n",
              "      <td>2019-05</td>\n",
              "      <td>14</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9138</th>\n",
              "      <td>ZION</td>\n",
              "      <td>IL</td>\n",
              "      <td>2019-06</td>\n",
              "      <td>9</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9139</th>\n",
              "      <td>ZION</td>\n",
              "      <td>IL</td>\n",
              "      <td>2019-07</td>\n",
              "      <td>11</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9140 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             city state year_month  sales_qty      perc\n",
              "0       ABBEVILLE    LA    2019-05         17  1.000000\n",
              "1       ABBEVILLE    LA    2019-06          6  1.000000\n",
              "2       ABBEVILLE    LA    2019-07         11  1.000000\n",
              "3        ABERDEEN    MD    2019-05         15  0.145631\n",
              "4        ABERDEEN    MD    2019-06          8  0.085106\n",
              "...           ...   ...        ...        ...       ...\n",
              "9135  ZEPHYRHILLS    FL    2019-06         10  1.000000\n",
              "9136  ZEPHYRHILLS    FL    2019-07         23  1.000000\n",
              "9137         ZION    IL    2019-05         14  1.000000\n",
              "9138         ZION    IL    2019-06          9  1.000000\n",
              "9139         ZION    IL    2019-07         11  1.000000\n",
              "\n",
              "[9140 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1XzRaUYB6Ke",
        "outputId": "9df15869-b6a4-42ef-a4b0-519cbd9a1cad"
      },
      "source": [
        "#Agora, um estoque estimado\n",
        "novo_estoque = pd.DataFrame()\n",
        "for ym in estoque['year_month'].unique():\n",
        "  for cid in estoque.loc[estoque['year_month']==ym,'city']:\n",
        "    reestoque=estoque.loc[(estoque['year_month']==ym)&(estoque['city']==cid)]['supplied_qty']\n",
        "    reestoque = reestoque.item() if len(reestoque>0) else 0\n",
        "    deestoque=0\n",
        "    vendas_local = vendas_mensais_cidades.loc[(vendas_mensais_cidades['year_month']==ym)&(vendas_mensais_cidades['city']==cid)].sort_values(by=['sales_qty'],ascending=[True])\n",
        "    saldo=0\n",
        "    n_iter=len(vendas_local)\n",
        "    reg=None\n",
        "    n_cid=0\n",
        "    if n_iter == 0: #Não houve venda nessa cidade nesse mês\n",
        "      n_cid=len(cidades.loc[cid])\n",
        "      if n_cid == 1:\n",
        "        novo_estoque=pd.concat([novo_estoque,pd.DataFrame({'year_month':ym,'city':cid, 'state':cidades.loc[cid], 'supplied_qty':reestoque},index=[0])],ignore_index=True)\n",
        "      else:\n",
        "        for i, st in enumerate([x[0] for x in cidades.loc[cid].to_numpy()]):\n",
        "          if i < n_cid - 1:\n",
        "            deestoque=ceil(reestoque/n_cid)\n",
        "          else:\n",
        "            deestoque=reestoque-saldo\n",
        "          saldo += deestoque\n",
        "          novo_estoque=pd.concat([novo_estoque,pd.DataFrame({'year_month':ym,'city':cid, 'state':st, 'supplied_qty':reestoque},index=[0])],ignore_index=True)\n",
        "    else:\n",
        "      for i,reg in enumerate([x[1] for x in vendas_local.iterrows()]):\n",
        "        if i < n_iter-1:\n",
        "          deestoque = ceil(reg['perc']*reestoque)\n",
        "        else:\n",
        "          deestoque=reestoque-saldo # Para a cidade com a maior venda, um ajuste de eventuais arredondamentos, pois a variável é discreta\n",
        "        saldo+=deestoque\n",
        "        novo_estoque=pd.concat([novo_estoque,pd.DataFrame({'year_month':ym,'city':cid, 'state':reg['state'], 'supplied_qty':deestoque}, index=[0])],ignore_index=True)\n",
        "      assert(saldo-reestoque==0)\n",
        "print(f\"Total estoque original: {estoque['supplied_qty'].sum()}. Total estoque estimado: {novo_estoque['supplied_qty'].sum()}. Diferença de {abs(estoque['supplied_qty'].sum()-novo_estoque['supplied_qty'].sum())}\")\n",
        "assert(estoque['supplied_qty'].sum()==novo_estoque['supplied_qty'].sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total estoque original: 592588. Total estoque estimado: 592588. Diferença de 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "MrqjwVJ-B9b5",
        "outputId": "ba4d34de-57b0-4fb8-cc36-c88d281dc169"
      },
      "source": [
        "teste=pd.merge(novo_estoque.groupby(by=['year_month','city']).agg({'supplied_qty':'sum'}).reset_index(),estoque,on=['year_month','city'],how='outer',suffixes=('_novo','original'))\n",
        "teste[teste['supplied_qty_novo']!=teste['supplied_qtyoriginal']] #Conferir se alguma cidade ficou com reestocagem incorreta comparando com sua informação original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year_month</th>\n",
              "      <th>city</th>\n",
              "      <th>supplied_qty_novo</th>\n",
              "      <th>supplied_qtyoriginal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [year_month, city, supplied_qty_novo, supplied_qtyoriginal]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDcdRVsJCvXS"
      },
      "source": [
        "#Movimentação do estoque\n",
        "def calcular_derivada(z):\n",
        "  regressor = linear_model.LinearRegression()\n",
        "  datas = np.array([datetime.strptime(x + '-01', '%Y-%m-%d').date() for x in z['year_month']])\n",
        "  redatas = np.array([(x - datas.min()).days for x in datas]).reshape(-1,1)\n",
        "  regressor.fit(X=redatas, y=z['excedente'])\n",
        "  return regressor.coef_[0]\n",
        "  \n",
        "expansao_vendas=pd.merge(vendas,lojas,on=['storeid'],how='left')\n",
        "vendas_cidades=expansao_vendas.groupby(by=['year_month','city','state']).agg({'sales_qty':'sum'}).reset_index()\n",
        "movimentacao_estoque = pd.merge(vendas_cidades,novo_estoque, on=['city','state','year_month'],how='outer')\n",
        "movimentacao_estoque.loc[:,'supplied_qty']=movimentacao_estoque.loc[:,'supplied_qty'].fillna(0).astype(np.int32) #Onde não há registro de reestoque, vale a pena considerar reestoque igual a 0\n",
        "cidades_cujos_estoques_nao_diminuiram=movimentacao_estoque[movimentacao_estoque['sales_qty'].isna()]['city']\n",
        "for cid in cidades_cujos_estoques_nao_diminuiram:\n",
        "  if len(cidades.loc[cid]) > 1:\n",
        "    print(f\"A cidade {cid} possui homônimas em outros estados\")\n",
        "  elif len(cidades.loc[cid])==0:\n",
        "    raise RuntimeError('Tem de ver isso aqui.')\n",
        "  else:\n",
        "    movimentacao_estoque.loc[(movimentacao_estoque['city']==cid)&(movimentacao_estoque['state'].isna()),'state']=cidades.loc[cid].item()\n",
        "    movimentacao_estoque.loc[(movimentacao_estoque['city']==cid)&(movimentacao_estoque['sales_qty'].isna()),'sales_qty']=0\n",
        "movimentacao_estoque.loc[:, 'sales_qty'] = movimentacao_estoque.loc[:, 'sales_qty'].astype(np.int32)\n",
        "movimentacao_estoque['venda_acumulada'] = movimentacao_estoque.groupby(by=['city', 'state'])['sales_qty'].transform(pd.Series.cumsum)\n",
        "movimentacao_estoque['estoque_acumulado'] = movimentacao_estoque.groupby(by=['city','state'])['supplied_qty'].transform(pd.Series.cumsum)\n",
        "movimentacao_estoque['excedente'] = movimentacao_estoque['estoque_acumulado'] - movimentacao_estoque['venda_acumulada']\n",
        "situacao_cidades = pd.merge(movimentacao_estoque.groupby(by=['city','state']).apply(calcular_derivada).rename('tendencia').reset_index(),zipes,on=['city','state'],how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtCX9gX9C0_M"
      },
      "source": [
        "#Situações\n",
        "manutencao = vendas.loc[(vendas['date_of_sales'] > pd.to_datetime('2019-06-01')) & (vendas['date_of_sales'] < pd.to_datetime('2019-07-01'))].groupby(by=['date_of_sales', 'storeid']).agg({'sales_qty': 'sum'}).reset_index().groupby(by=['storeid']).agg(vendas_manutencao=('sales_qty', 'mean'))\n",
        "condicao_ultima_semana = vendas.loc[vendas['date_of_sales'] > pd.to_datetime('2019-07-01')].groupby(by=['date_of_sales','storeid']).sum().reset_index().groupby(by=['storeid']).agg(vendas_ultima_semana=('sales_qty', 'mean'))\n",
        "condicoes_preexistentes=pd.merge(manutencao,condicao_ultima_semana,left_index=True,right_index=True,how='outer')\n",
        "for col in ['vendas_manutencao', 'vendas_ultima_semana']:\n",
        "  condicoes_preexistentes.loc[:, col] = condicoes_preexistentes.loc[:, col].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XNudd7VEPNb"
      },
      "source": [
        "# Visualização situacional\n",
        "fig, ax = plt.subplots(nrows=3,sharex=True,figsize=(16, 15))\n",
        "vendas_resumo = vendas.groupby(by=['date_of_sales', 'product']).agg(vendas=('sales_qty', 'sum')).reset_index()\n",
        "vendas_resumo['medias'] = 0\n",
        "estoque_resumo = pd.merge(estoque.groupby(by='year_month').agg({'supplied_qty': 'sum'}),vendas.groupby(by=['year_month']).agg({'sales_qty': 'sum'}),left_index=True,right_index=True,how='inner').reset_index()\n",
        "estoque_resumo['data_ref'] = estoque_resumo.loc[:, 'year_month'].apply(lambda z: pd.to_datetime(z + '-15'))\n",
        "estoque_resumo['saldo']=estoque_resumo['supplied_qty']-estoque_resumo['sales_qty']\n",
        "for prod in vendas_resumo['product'].unique():\n",
        "  vendas_resumo.loc[vendas_resumo['product']==prod,'medias']=vendas_resumo.loc[vendas_resumo['product']==prod,'vendas'].rolling(window=7, min_periods=1).mean()\n",
        "sbn.lineplot(data=vendas_resumo, x='date_of_sales', y='vendas', hue='product', palette='Set2', ax=ax[0])\n",
        "_=ax[0].set_ylabel(\"Vendas diárias por produto.\")\n",
        "sbn.lineplot(data=vendas_resumo, x='date_of_sales', y='medias', hue='product', palette='Set2', ax=ax[1])\n",
        "_ = ax[1].set_ylabel(\"Média móvel de vendas de 7 dias\")\n",
        "sbn.lineplot(data=estoque_resumo, x='data_ref', y='supplied_qty', ax=ax[2], color='tab:cyan')\n",
        "# ax[2].plot(estoque_resumo['data_ref'],estoque_resumo['supplied_data'],'')\n",
        "axt = ax[2].twinx()\n",
        "sbn.lineplot(data=estoque_resumo, x='data_ref', y='saldo', ax=axt, color='tab:red')\n",
        "_ = ax[2].set_ylabel('Total reestocado')\n",
        "_ = ax[2].set_xlabel('Data de refência')\n",
        "_ = axt.set_ylabel('Saldo de Estoque')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBkl54HEEPKt"
      },
      "source": [
        "#Histograma graduado de variação\n",
        "e_c = 0\n",
        "e_m = 0.1\n",
        "e_a = 0.5\n",
        "fig,ax = plt.subplots(figsize=(16,10))\n",
        "sbn.histplot(data=situacao_cidades, x='tendencia', binwidth=0.05, ax=ax)\n",
        "ax.set_title('Crescimento do estoque nos municípios')\n",
        "ax.set_ylabel(\"N° de cidades\")\n",
        "ax.set_xlabel(\"Intensidade do crescimento\")\n",
        "for pat in ax.patches:\n",
        "  if pat.get_x() < e_c:\n",
        "    pat.set_ec('darkred')\n",
        "    pat.set_fc('tab:red')\n",
        "  elif pat.get_x() < e_m:\n",
        "    pat.set_ec('darkgreen')\n",
        "    pat.set_fc('seagreen')\n",
        "  elif pat.get_x() < e_a:\n",
        "    pat.set_ec('darkslategrey')\n",
        "    pat.set_fc('lightslategrey')\n",
        "  else:\n",
        "    pat.set_ec('darkorange')\n",
        "    pat.set_fc('orange')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyX8uhaEPHw"
      },
      "source": [
        "for i in range(len(mapa_counties['features'])):\n",
        "  fips = mapa_counties['features'][i]['properties']['FIPS_CODE']\n",
        "  cidades_dentro_county = situacao_cidades[situacao_cidades['county_fips'] == fips]\n",
        "  td = 'Sem vendas neste condado.'\n",
        "  tend = '-'\n",
        "  if len(cidades_dentro_county) > 0:\n",
        "    tend = cidades_dentro_county['tendencia'].max() if cidades_dentro_county['tendencia'].min() >= 0 else cidades_dentro_county['tendencia'].min()\n",
        "    td = \"{:.2f} %\".format(tend * 100)\n",
        "  mapa_counties['features'][i]['properties']['Tendência'] = td\n",
        "  mapa_counties['features'][i]['properties']['tend'] = tend\n",
        "ob_mapa_counties = fl.Map(location=[39.833333, -98.585522], zoom_start=4)\n",
        "fl.GeoJson(\n",
        "  mapa_counties,\n",
        "  name=\"Evolução do estoque dos condados\",\n",
        "  style_function=colorizar_county,\n",
        "  tooltip=fl.GeoJsonTooltip(fields=('COUNTY_STATE_NAME','Tendência'),style=\"font-family: Roboto;\")\n",
        ").add_to(ob_mapa_counties)\n",
        "ob_mapa_counties"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p9ZRoEGEPBk"
      },
      "source": [
        "#Preencher o que der\n",
        "preenchimento_das_vendas = pd.DataFrame()\n",
        "todos_produtos = vendas['product'].unique()\n",
        "#Maio\n",
        "for mes in [5]:\n",
        "  for dia in range(1, 32):\n",
        "    data_ref = pd.to_datetime(f\"2019-{mes:02n}-{dia:02n}\")\n",
        "    extrato = vendas.loc[vendas['date_of_sales'] == data_ref]\n",
        "    if len(extrato) == 0:\n",
        "      dia_da_semana = data_ref.dayofweek\n",
        "      qto_dias_no_mes = [x for x in [pd.to_datetime(f\"2019-{mes:02n}-{x:02n}\") for x in range(1, 32)] if x.dayofweek == dia_da_semana]\n",
        "      vendas_no_mes=pd.DataFrame()\n",
        "      for loja in lojas['storeid'].unique():\n",
        "        vendas_realizadas_no_mes = vendas[(vendas['storeid'] == loja) & (vendas['date_of_sales'].isin(qto_dias_no_mes))].copy()\n",
        "        for prod in todos_produtos:\n",
        "          if len(vendas_realizadas_no_mes[vendas_realizadas_no_mes['product'] == prod]) > 0:\n",
        "            venda_media_dia_semana = vendas_realizadas_no_mes[vendas_realizadas_no_mes['product'] == prod]['sales_qty'].sum() / (len(qto_dias_no_mes)-1)\n",
        "            vendas_no_mes = pd.concat([vendas_no_mes,\n",
        "              pd.DataFrame.from_dict({0:[data_ref,prod,venda_media_dia_semana,loja]},columns=['date_of_sales','product','sales_qty','storeid'],orient='index')\n",
        "            ],ignore_index=True)\n",
        "      preenchimento_das_vendas = pd.concat([preenchimento_das_vendas, vendas_no_mes], ignore_index=True, copy=True, sort=True)\n",
        "#Julho\n",
        "for mes in [7]:\n",
        "  for dia in range(20, 32):\n",
        "    data_ref = pd.to_datetime(f\"2019-{mes:02n}-{dia:02n}\")\n",
        "    dia_da_semana = data_ref.dayofweek\n",
        "    datas_dos_dias_da_semana = [x for x in [pd.to_datetime(f\"2019-{mes:02n}-{x:02n}\") for x in range(1, 32)] if x.dayofweek == dia_da_semana]\n",
        "    for loja in lojas['storeid'].unique():\n",
        "      vendas_realizadas_nos_dias_da_semana = vendas[(vendas['date_of_sales'].dt.month == mes) & (vendas['date_of_sales'].isin(datas_dos_dias_da_semana)) & (vendas['storeid']==loja)]\n",
        "      for prod in todos_produtos:\n",
        "        if len(vendas_realizadas_nos_dias_da_semana[vendas_realizadas_nos_dias_da_semana['product'] == prod]) > 0:\n",
        "          vendas_medias_observadas = vendas_realizadas_nos_dias_da_semana[vendas_realizadas_nos_dias_da_semana['product'] == prod].groupby(\n",
        "            by=['storeid','product']\n",
        "          ).agg('mean').reset_index()\n",
        "          vendas_medias_observadas['date_of_sales']=data_ref\n",
        "          preenchimento_das_vendas = pd.concat([preenchimento_das_vendas, vendas_medias_observadas], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMuVmh6_EO8C"
      },
      "source": [
        "#Reconsolidar_tudo\n",
        "vendas_compensadas = pd.concat([vendas.drop(labels=['year_month'], axis=1), preenchimento_das_vendas], ignore_index=True, copy=True, sort=True)\n",
        "vendas_compensadas['year_month'] = vendas_compensadas['date_of_sales'].dt.strftime('%Y-%m')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeM110xLEO2M"
      },
      "source": [
        "#Estoque estimado para agosto igual à reestocagem de julho\n",
        "extrato_estoque_agosto = novo_estoque[novo_estoque['year_month'] == '2019-07'].copy()\n",
        "extrato_estoque_agosto.loc[:,'year_month']='2019-08'\n",
        "estoque_previsoes = pd.concat([novo_estoque, extrato_estoque_agosto], ignore_index=True, copy=True, sort=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoD-m7nBEOzZ"
      },
      "source": [
        "situacao_cidades_original = situar_cidades(vendas_compensadas, novo_estoque)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-LcbGZzEOwg"
      },
      "source": [
        "# Se agosto for como maio\n",
        "extrato_vendas_agosto = vendas_compensadas[vendas_compensadas['date_of_sales'].dt.month == 5].copy()\n",
        "extrato_vendas_agosto.loc[:, 'date_of_sales'] = extrato_vendas_agosto.loc[:, 'date_of_sales'].apply(lambda z: pd.to_datetime(z.to_pydatetime().replace(month=8)))\n",
        "extrato_vendas_agosto['year_month'] = '2019-08'\n",
        "vendas_agosto_maio = pd.concat([vendas_compensadas, extrato_vendas_agosto], copy=True, sort=True, ignore_index=True)\n",
        "situacao_cidades_agosto_maio = situar_cidades(vendas_agosto_maio,estoque_previsoes)\n",
        "\n",
        "# Se agosto for como julho\n",
        "extrato_vendas_agosto = vendas_compensadas[vendas_compensadas['date_of_sales'].dt.month == 7].copy()\n",
        "extrato_vendas_agosto.loc[:, 'date_of_sales'] = extrato_vendas_agosto.loc[:, 'date_of_sales'].apply(lambda z: pd.to_datetime(z.to_pydatetime().replace(month=8)))\n",
        "extrato_vendas_agosto['year_month'] = '2019-08'\n",
        "vendas_agosto_julho = pd.concat([vendas_compensadas, extrato_vendas_agosto], copy=True, sort=True, ignore_index=True)\n",
        "situacao_cidades_agosto_julho = situar_cidades(vendas_agosto_julho,estoque_previsoes)\n",
        "\n",
        "# Se agosto for 50% a mais que julho\n",
        "extrato_vendas_agosto.loc[:, 'sales_qty'] = extrato_vendas_agosto.loc[:, 'sales_qty'] * 1.5\n",
        "vendas_agosto_julho_1_5 = pd.concat([vendas_compensadas, extrato_vendas_agosto], copy=True, sort=True, ignore_index=True)\n",
        "situacao_cidades_agosto_julho_1_5 = situar_cidades(vendas_agosto_julho_1_5,estoque_previsoes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxcPPblvEOtZ"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=4,ncols=1, figsize=(16, 20))\n",
        "plotar_histograma_da_situacao_do_estoque_das_cidades(situacao_cidades_original, ax[0])\n",
        "plotar_histograma_da_situacao_do_estoque_das_cidades(situacao_cidades_agosto_maio, ax[1])\n",
        "plotar_histograma_da_situacao_do_estoque_das_cidades(situacao_cidades_agosto_julho, ax[2])\n",
        "plotar_histograma_da_situacao_do_estoque_das_cidades(situacao_cidades_agosto_julho_1_5, ax[3])\n",
        "for i, lab in enumerate([None, None, None, 'Tendência de variação do Estoque']):\n",
        "  ax[i].set_xlabel(lab)\n",
        "for i, lab in enumerate([\n",
        "  'Estoques com preenchimento das vendas de julho',\n",
        "  'Estoques caso as vendas em agosto estejam no patamar de maio',\n",
        "  'Estoques caso as vendas em agosto estejam como o previsto para julho',\n",
        "  'Estoques caso as vendas em agosto estejam 50% acima do previsto para julho'\n",
        "]):\n",
        "  ax[i].set_title(lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcozaQGhEOqi"
      },
      "source": [
        "fig, ax = plt.subplots(ncols=2, nrows=4, figsize=(16, 20), sharex=True)\n",
        "plotar_vendas_diarias_e_estoque(vendas_compensadas,novo_estoque,ax[0])\n",
        "plotar_vendas_diarias_e_estoque(vendas_agosto_maio, estoque_previsoes, ax[1])\n",
        "plotar_vendas_diarias_e_estoque(vendas_agosto_julho, estoque_previsoes, ax[2])\n",
        "plotar_vendas_diarias_e_estoque(vendas_agosto_julho_1_5, estoque_previsoes, ax[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5RxxefPEOnb"
      },
      "source": [
        "for i in range(len(mapa_counties['features'])):\n",
        "  fips = mapa_counties['features'][i]['properties']['FIPS_CODE']\n",
        "  cidades_dentro_county = situacao_cidades_original[situacao_cidades_original['county_fips'] == fips]\n",
        "  td = 'Sem vendas neste condado.'\n",
        "  tend = '-'\n",
        "  if len(cidades_dentro_county) > 0:\n",
        "    tend = cidades_dentro_county['tendencia'].max() if cidades_dentro_county['tendencia'].min() >= 0 else cidades_dentro_county['tendencia'].min()\n",
        "    td = \"{:.2f} %\".format(tend * 100)\n",
        "  mapa_counties['features'][i]['properties']['Tendência'] = td\n",
        "  mapa_counties['features'][i]['properties']['tend'] = tend\n",
        "ob_mapa_counties_original = fl.Map(location=[39.833333, -98.585522], zoom_start=4)\n",
        "fl.GeoJson(\n",
        "  mapa_counties,\n",
        "  name=\"Evolução do estoque dos condados\",\n",
        "  style_function=colorizar_county,\n",
        "  tooltip=fl.GeoJsonTooltip(fields=('COUNTY_STATE_NAME','Tendência'),style=\"font-family: Roboto;\")\n",
        ").add_to(ob_mapa_counties_original)\n",
        "ob_mapa_counties_original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SMwbb4dEOkc"
      },
      "source": [
        "for i in range(len(mapa_counties['features'])):\n",
        "  fips = mapa_counties['features'][i]['properties']['FIPS_CODE']\n",
        "  cidades_dentro_county = situacao_cidades_agosto_maio[situacao_cidades_agosto_maio['county_fips'] == fips]\n",
        "  td = 'Sem vendas neste condado.'\n",
        "  tend = '-'\n",
        "  if len(cidades_dentro_county) > 0:\n",
        "    tend = cidades_dentro_county['tendencia'].max() if cidades_dentro_county['tendencia'].min() >= 0 else cidades_dentro_county['tendencia'].min()\n",
        "    td = \"{:.2f} %\".format(tend * 100)\n",
        "  mapa_counties['features'][i]['properties']['Tendência'] = td\n",
        "  mapa_counties['features'][i]['properties']['tend'] = tend\n",
        "ob_mapa_counties_agosto_maio = fl.Map(location=[39.833333, -98.585522], zoom_start=4)\n",
        "fl.GeoJson(\n",
        "  mapa_counties,\n",
        "  name=\"Evolução do estoque dos condados\",\n",
        "  style_function=colorizar_county,\n",
        "  tooltip=fl.GeoJsonTooltip(fields=('COUNTY_STATE_NAME','Tendência'),style=\"font-family: Roboto;\")\n",
        ").add_to(ob_mapa_counties_agosto_maio)\n",
        "ob_mapa_counties_agosto_maio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va2w___vEOhk"
      },
      "source": [
        "for i in range(len(mapa_counties['features'])):\n",
        "  fips = mapa_counties['features'][i]['properties']['FIPS_CODE']\n",
        "  cidades_dentro_county = situacao_cidades_agosto_julho[situacao_cidades_agosto_julho['county_fips'] == fips]\n",
        "  td = 'Sem vendas neste condado.'\n",
        "  tend = '-'\n",
        "  if len(cidades_dentro_county) > 0:\n",
        "    tend = cidades_dentro_county['tendencia'].max() if cidades_dentro_county['tendencia'].min() >= 0 else cidades_dentro_county['tendencia'].min()\n",
        "    td = \"{:.2f} %\".format(tend * 100)\n",
        "  mapa_counties['features'][i]['properties']['Tendência'] = td\n",
        "  mapa_counties['features'][i]['properties']['tend'] = tend\n",
        "ob_mapa_counties_agosto_julho = fl.Map(location=[39.833333, -98.585522], zoom_start=4)\n",
        "fl.GeoJson(\n",
        "  mapa_counties,\n",
        "  name=\"Evolução do estoque dos condados\",\n",
        "  style_function=colorizar_county,\n",
        "  tooltip=fl.GeoJsonTooltip(fields=('COUNTY_STATE_NAME','Tendência'),style=\"font-family: Roboto;\")\n",
        ").add_to(ob_mapa_counties_agosto_julho)\n",
        "ob_mapa_counties_agosto_julho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6RYrtCAEOe6"
      },
      "source": [
        "for i in range(len(mapa_counties['features'])):\n",
        "  fips = mapa_counties['features'][i]['properties']['FIPS_CODE']\n",
        "  cidades_dentro_county = situacao_cidades_agosto_julho_1_5[situacao_cidades_agosto_julho_1_5['county_fips'] == fips]\n",
        "  td = 'Sem vendas neste condado.'\n",
        "  tend = '-'\n",
        "  if len(cidades_dentro_county) > 0:\n",
        "    tend = cidades_dentro_county['tendencia'].max() if cidades_dentro_county['tendencia'].min() >= 0 else cidades_dentro_county['tendencia'].min()\n",
        "    td = \"{:.2f} %\".format(tend * 100)\n",
        "  mapa_counties['features'][i]['properties']['Tendência'] = td\n",
        "  mapa_counties['features'][i]['properties']['tend'] = tend\n",
        "ob_mapa_counties_agosto_julho_1_5 = fl.Map(location=[39.833333, -98.585522], zoom_start=4)\n",
        "fl.GeoJson(\n",
        "  mapa_counties,\n",
        "  name=\"Evolução do estoque dos condados\",\n",
        "  style_function=colorizar_county,\n",
        "  tooltip=fl.GeoJsonTooltip(fields=('COUNTY_STATE_NAME','Tendência'),style=\"font-family: Roboto;\")\n",
        ").add_to(ob_mapa_counties_agosto_julho_1_5)\n",
        "ob_mapa_counties_agosto_julho_1_5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X51XtABIEObs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUAATFHEOZC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Ai9TUlEOV-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkt3nWhPEOQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz7BuAQVEONW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
